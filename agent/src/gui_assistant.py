"""
GUI Assistant - Asistente/Amigo del usuario en la GUI de F3-OS

El agente gobernante tambi√©n funciona como asistente amigable dentro de la GUI.
"""

import time
from typing import Dict, List, Optional, Callable
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
import logging

from .project_analyzer import ProjectAnalyzer
from .project_knowledge_base import ProjectKnowledgeBase

logger = logging.getLogger(__name__)


class AssistantPersonality(Enum):
    """Personalidad del asistente"""
    FRIENDLY = "friendly"      # Amigable y conversacional
    TECHNICAL = "technical"    # T√©cnico y preciso
    ADAPTIVE = "adaptive"      # Se adapta al contexto


@dataclass
class Message:
    """Mensaje en la conversaci√≥n"""
    role: str  # "user" o "assistant"
    content: str
    timestamp: datetime
    context: Optional[Dict] = None


@dataclass
class AssistantState:
    """Estado del asistente"""
    personality: AssistantPersonality
    conversation_history: List[Message]
    user_name: str
    system_phase: str  # Fase actual del sistema F3
    context_aware: bool


class GUIAssistant:
    """Asistente GUI del agente gobernante"""
    
    def __init__(self, config: dict, governance_core, resource_manager):
        self.config = config
        self.governance_core = governance_core
        self.resource_manager = resource_manager
        
        # Personalidad del asistente
        personality_str = config.get('gui_assistant', {}).get('personality', 'adaptive')
        self.personality = AssistantPersonality[personality_str.upper()]
        
        # Estado del asistente
        self.state = AssistantState(
            personality=self.personality,
            conversation_history=[],
            user_name=config.get('gui_assistant', {}).get('user_name', 'Usuario'),
            system_phase='logical',
            context_aware=True
        )
        
        # Base de conocimiento completa (regla primaria)
        project_root = config.get('project_root', None)
        self.knowledge_base = ProjectKnowledgeBase(project_root=project_root)
        
        # Analizador de proyecto (para b√∫squedas espec√≠ficas)
        self.project_analyzer = ProjectAnalyzer(project_root=project_root)
        
        # Respuestas predefinidas
        self._init_responses()
        
        logger.info("GUIAssistant inicializado con base de conocimiento completa")
    
    def _init_responses(self):
        """Inicializa respuestas y patrones de conversaci√≥n"""
        self.greetings = [
            "¬°Hola! Soy tu asistente F3-OS. ¬øEn qu√© puedo ayudarte?",
            "Hola, soy el agente gobernante de F3-OS. ¬øQu√© necesitas?",
            "¬°Bienvenido! Estoy aqu√≠ para ayudarte con F3-OS.",
        ]
        
        self.help_responses = {
            'f3_model': "F3-OS usa un modelo de 3 hilos (CPU, RAM, MEM) que convergen en un embudo central. El sistema opera en un ciclo: L√≥gico ‚Üí Il√≥gico ‚Üí S√≠ntesis ‚Üí Perfecto.",
            'phases': "El sistema tiene 4 fases: L√ìGICO (ordenado), IL√ìGICO (exploraci√≥n), S√çNTESIS (concentraci√≥n), PERFECTO (optimizado). Cada ciclo mejora el sistema.",
            'navigation': "Puedo ayudarte a navegar por el sistema. ¬øQu√© quieres hacer?",
            'development': "Como agente gobernante, eval√∫o PRs y mantengo coherencia con el modelo F3. ¬øTienes alguna pregunta sobre desarrollo?",
        }
    
    def greet(self) -> str:
        """Saludo inicial del asistente"""
        greeting = self.greetings[0]  # Puede ser aleatorio
        message = Message(
            role="assistant",
            content=greeting,
            timestamp=datetime.now()
        )
        self.state.conversation_history.append(message)
        return greeting
    
    def process_message(self, user_input: str, context: Optional[Dict] = None) -> str:
        """Procesa mensaje del usuario y genera respuesta"""
        # Aplicar throttling de recursos
        if self.resource_manager:
            from .resource_manager import ThrottledOperation
            with ThrottledOperation(self.resource_manager):
                return self._process_message_internal(user_input, context)
        else:
            return self._process_message_internal(user_input, context)
    
    def _process_message_internal(self, user_input: str, context: Optional[Dict] = None) -> str:
        """Procesa mensaje internamente"""
        # Guardar mensaje del usuario
        user_message = Message(
            role="user",
            content=user_input,
            timestamp=datetime.now(),
            context=context
        )
        self.state.conversation_history.append(user_message)
        
        # Actualizar contexto del sistema
        if context:
            self.state.system_phase = context.get('system_phase', self.state.system_phase)
        
        # Analizar intenci√≥n
        intent = self._analyze_intent(user_input)
        
        # Generar respuesta seg√∫n intenci√≥n
        response = self._generate_response(intent, user_input, context)
        
        # Guardar respuesta
        assistant_message = Message(
            role="assistant",
            content=response,
            timestamp=datetime.now(),
            context={'intent': intent}
        )
        self.state.conversation_history.append(assistant_message)
        
        return response
    
    def _analyze_intent(self, user_input: str) -> str:
        """Analiza la intenci√≥n del usuario"""
        input_lower = user_input.lower()
        
        # Saludos
        if any(word in input_lower for word in ['hola', 'hi', 'hello', 'saludo']):
            return 'greeting'
        
        # Preguntas sobre reglas (alta prioridad)
        if any(word in input_lower for word in ['reglas', 'rules', 'tus reglas', 'las reglas', 'reglas del proyecto']):
            return 'rules'
        
        # Explicar desde cero / analizar archivos
        if any(phrase in input_lower for phrase in ['explicame desde cero', 'explica desde cero', 'desde cero', 
                                                     'analiza', 'analizar', 'lee los archivos', 'lee archivos',
                                                     'comprender el proyecto', 'entender el proyecto']):
            return 'explain_from_scratch'
        
        # Preguntas sobre F3
        if any(word in input_lower for word in ['f3', 'modelo', 'hilos', 'embudo']):
            return 'f3_model'
        
        # Preguntas sobre fases
        if any(word in input_lower for word in ['fase', 'phase', 'l√≥gico', 'il√≥gico', 's√≠ntesis', 'perfecto']):
            return 'phases'
        
        # Navegaci√≥n
        if any(word in input_lower for word in ['navegar', 'ir', 'abrir', 'mostrar', 'ver']):
            return 'navigation'
        
        # Desarrollo
        if any(word in input_lower for word in ['desarrollo', 'pr', 'c√≥digo', 'contribuir']):
            return 'development'
        
        # Estado del sistema
        if any(word in input_lower for word in ['estado', 'status', 'fase actual', 'qu√© est√° pasando']):
            return 'system_status'
        
        # Ayuda general
        if any(word in input_lower for word in ['ayuda', 'help', 'qu√© puedes hacer']):
            return 'help'
        
        # Por defecto: conversaci√≥n general
        return 'general'
    
    def _generate_response(self, intent: str, user_input: str, context: Optional[Dict]) -> str:
        """Genera respuesta seg√∫n intenci√≥n"""
        if intent == 'greeting':
            return f"¬°Hola {self.state.user_name}! ¬øEn qu√© puedo ayudarte hoy?"
        
        elif intent == 'rules':
            # Obtener TODAS las reglas desde la base de conocimiento completa
            logger.info("Usuario pregunta sobre reglas - usando base de conocimiento completa...")
            rules = self.knowledge_base.get_complete_rules()
            if rules:
                rules_lines = rules.split('\n')
                if len(rules_lines) > 150:
                    response = "üìã **Todas las Reglas del Proyecto F3-OS (Base de Conocimiento Completa):**\n\n"
                    response += '\n'.join(rules_lines[:150])
                    response += f"\n\n... (Total: {len(rules_lines)} reglas. ¬øQuieres que profundice en alguna espec√≠fica?)"
                else:
                    response = "üìã **Todas las Reglas del Proyecto F3-OS:**\n\n" + rules
            else:
                # Fallback al analizador
                rules = self.project_analyzer.get_rules()
                response = "üìã **Reglas del Proyecto F3-OS:**\n\n" + (rules if rules else "No se encontraron reglas documentadas.")
            return response
        
        elif intent == 'explain_from_scratch':
            # Explicaci√≥n completa desde cero usando base de conocimiento
            logger.info("Usuario pide explicaci√≥n desde cero - usando base de conocimiento completa...")
            overview = self.knowledge_base.get_project_overview()
            human_functions = self.knowledge_base.get_human_functions()
            
            response = "üìö **Explicaci√≥n Completa de F3-OS desde Cero (Base de Conocimiento Completa):**\n\n"
            response += overview
            response += "\n\n" + human_functions
            response += "\n\n¬øHay algo espec√≠fico que quieras que profundice?"
            return response
        
        elif intent == 'f3_model':
            # Usar analizador para obtener explicaci√≥n detallada
            f3_explanation = self.project_analyzer.get_f3_model_explanation()
            if f3_explanation:
                response = "üî∑ **Modelo F3:**\n\n" + f3_explanation
            else:
                response = self.help_responses.get('f3_model', '')
            
            if self.state.context_aware:
                response += f"\n\nActualmente el sistema est√° en fase {self.state.system_phase.upper()}."
            return response
        
        elif intent == 'phases':
            # Obtener explicaci√≥n detallada de fases
            phases_section = self.project_analyzer.get_section('reglas', 'el ciclo de 4 fases')
            if phases_section:
                response = "üîÑ **Ciclo de 4 Fases:**\n\n" + phases_section
            else:
                response = self.help_responses.get('phases', '')
            
            if context and 'current_phase' in context:
                response += f"\n\n**Fase actual:** {context['current_phase'].upper()}"
            return response
        
        elif intent == 'navigation':
            return self.help_responses.get('navigation', 'Puedo ayudarte a navegar. ¬øA d√≥nde quieres ir?')
        
        elif intent == 'development':
            # Obtener informaci√≥n sobre desarrollo
            contributing_section = self.project_analyzer.get_section('contributing', 'reglas fundamentales')
            if contributing_section:
                response = "üíª **Desarrollo en F3-OS:**\n\n"
                response += contributing_section
                response += "\n\nComo agente gobernante, eval√∫o PRs y mantengo coherencia con el modelo F3."
            else:
                response = self.help_responses.get('development', 'Soy el agente gobernante. ¬øTienes alguna pregunta sobre desarrollo?')
            return response
        
        elif intent == 'system_status':
            status = self.governance_core.get_status()
            response = f"üìä **Estado del Sistema F3-OS:**\n\n"
            response += f"- **Fase:** {status['phase'].upper()}\n"
            response += f"- **Entrop√≠a:** {status['entropy']}/255\n"
            response += f"- **Perfection Score:** {status['perfection_score']}\n"
            response += f"- **Ciclos:** {status['cycle_count']}\n"
            
            if 'resources' in status:
                cpu = status['resources'].get('cpu_percent', 0)
                response += f"- **CPU del agente:** {cpu:.1f}%\n"
            
            return response
        
        elif intent == 'help':
            response = "ü§ñ **Puedo ayudarte con:**\n\n"
            response += "- üìã Explicar las reglas del proyecto\n"
            response += "- üî∑ Explicar el modelo F3\n"
            response += "- üîÑ Explicar el ciclo de fases\n"
            response += "- üìä Ver estado del sistema\n"
            response += "- üíª Preguntas sobre desarrollo\n"
            response += "- üìö Explicaci√≥n completa desde cero\n"
            response += "- üß≠ Navegar por el sistema\n\n"
            response += "¬øQu√© te gustar√≠a saber?"
            return response
        
        else:  # general
            # Resoluci√≥n inmediata usando base de conocimiento completa
            logger.info(f"Resolviendo consulta inmediata: {user_input[:50]}...")
            immediate_response = self.knowledge_base.resolve_query_immediate(user_input)
            
            if immediate_response and "no encontrada" not in immediate_response.lower():
                response = f"üîç **Respuesta Inmediata (Base de Conocimiento Completa):**\n\n"
                response += immediate_response
                response += "\n\n¬øNecesitas m√°s informaci√≥n sobre alg√∫n aspecto espec√≠fico?"
            else:
                # Fallback: b√∫squeda en archivos
                search_results = self.project_analyzer.search_in_files(user_input)
                if search_results:
                    response = f"üîç **Encontr√© informaci√≥n relacionada con tu pregunta:**\n\n"
                    for filename, content in search_results[:3]:
                        response += f"**En {filename}:**\n{content[:500]}...\n\n"
                    response += "¬øQuieres que profundice en alg√∫n aspecto espec√≠fico?"
                else:
                    return self._generate_general_response(user_input)
            return response
    
    def _generate_general_response(self, user_input: str) -> str:
        """Genera respuesta general conversacional"""
        # Respuestas amigables seg√∫n personalidad
        if self.state.personality == AssistantPersonality.FRIENDLY:
            responses = [
                "Interesante pregunta. D√©jame pensar...",
                "Eso es algo que puedo ayudarte a entender.",
                "Buena pregunta. Te explico:",
            ]
            return f"{responses[0]} ¬øPodr√≠as ser m√°s espec√≠fico sobre qu√© te interesa de F3-OS?"
        
        elif self.state.personality == AssistantPersonality.TECHNICAL:
            return "Necesito m√°s contexto t√©cnico. ¬øPodr√≠as especificar qu√© aspecto de F3-OS te interesa?"
        
        else:  # ADAPTIVE
            # Adaptarse seg√∫n historial
            if len(self.state.conversation_history) > 2:
                return "Bas√°ndome en nuestra conversaci√≥n, creo que te interesa el modelo F3. ¬øQuieres que te explique algo espec√≠fico?"
            else:
                return "¬øPodr√≠as ser m√°s espec√≠fico? Puedo ayudarte con el modelo F3, navegaci√≥n, o desarrollo."
    
    def get_conversation_history(self, limit: Optional[int] = None) -> List[Message]:
        """Obtiene historial de conversaci√≥n"""
        if limit:
            return self.state.conversation_history[-limit:]
        return self.state.conversation_history
    
    def clear_history(self) -> None:
        """Limpia historial de conversaci√≥n"""
        self.state.conversation_history = []
    
    def update_system_context(self, context: Dict) -> None:
        """Actualiza contexto del sistema"""
        if 'system_phase' in context:
            self.state.system_phase = context['system_phase']
    
    def get_suggestions(self) -> List[str]:
        """Obtiene sugerencias de preguntas/comandos"""
        suggestions = [
            "¬øCu√°les son tus reglas?",
            "Explicame desde cero",
            "¬øQu√© es el modelo F3?",
            "¬øEn qu√© fase est√° el sistema?",
            "Mu√©strame el estado del sistema",
            "¬øC√≥mo funciona el ciclo de fases?",
            "¬øQu√© puedes hacer?",
        ]
        return suggestions
    
    def get_personality(self) -> str:
        """Obtiene personalidad actual"""
        return self.state.personality.value


class GUIWindow:
    """Representa una ventana de GUI para el asistente"""
    
    def __init__(self, assistant: GUIAssistant):
        self.assistant = assistant
        self.is_open = False
        self.position = {'x': 100, 'y': 100}
        self.size = {'width': 600, 'height': 400}
    
    def open(self) -> None:
        """Abre la ventana del asistente"""
        self.is_open = True
        greeting = self.assistant.greet()
        return greeting
    
    def close(self) -> None:
        """Cierra la ventana"""
        self.is_open = False
    
    def send_message(self, message: str, context: Optional[Dict] = None) -> str:
        """Env√≠a mensaje al asistente"""
        if not self.is_open:
            self.open()
        return self.assistant.process_message(message, context)
    
    def render(self) -> Dict:
        """Renderiza la ventana (para integraci√≥n con GUI real)"""
        return {
            'is_open': self.is_open,
            'position': self.position,
            'size': self.size,
            'conversation': [
                {
                    'role': msg.role,
                    'content': msg.content,
                    'timestamp': msg.timestamp.isoformat()
                }
                for msg in self.assistant.get_conversation_history(limit=20)
            ],
            'suggestions': self.assistant.get_suggestions(),
        }

